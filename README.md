# Kasparro â€” High-Bar V2 Facebook Performance Analyst

**Author:** Suragani Yaswanth Sai

This repository implements a production-style multi-agent analytics system for diagnosing Facebook Ads performance changes.

It goes beyond a simple heuristic pipeline and includes:

  * Baseline vs Current segmentation
  * Metric deltas (absolute & relative)
  * Evidence-backed hypotheses
  * Strict evaluator with confidence modeling
  * Schema validation & drift detection
  * Full observability (JSONL logs per agent, readable logs, metrics)
  * Lightweight metrics layer
  * Retry logic
  * Complete test suite

**This version satisfies all requirements for P0 â†’ P1 â†’ P2 â†’ V2.**

-----

## ğŸš€ Quick Start

Ensure you have **Python \>= 3.10**.

```bash
# Check Python version
python -V

# Create virtual environment
python -m venv .venv

# Activate virtual environment
# Windows:
.venv\Scripts\activate
# macOS / Linux:
source .venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Run the pipeline
python src/run.py "Why did CTR drop?"
```

**Output files are written to:**

  * `reports/`
  * `logs/run_<timestamp>/`

-----

## ğŸ“ Project Structure

```text
Yaswanthsai_HighBar_V2/
â”œâ”€â”€ agent_graph.md
â”œâ”€â”€ Makefile
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.yaml
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ sample_fb_ads.csv
â”‚   â”œâ”€â”€ synthetic_fb_ads_undergarments.csv
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ prompts/
â”‚   â”œâ”€â”€ planner_prompt.md
â”‚   â”œâ”€â”€ insight_prompt.md
â”‚   â””â”€â”€ creative_prompt.md
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ run.py
â”‚   â”œâ”€â”€ orchestrator.py
â”‚   â”œâ”€â”€ utils.py
â”‚   â””â”€â”€ agents/
â”‚       â”œâ”€â”€ planner.py
â”‚       â”œâ”€â”€ data_agent.py
â”‚       â”œâ”€â”€ insight_agent.py
â”‚       â”œâ”€â”€ evaluator.py
â”‚       â””â”€â”€ creative_generator.py
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ run_<timestamp>/
â”‚       â”œâ”€â”€ planner.jsonl
â”‚       â”œâ”€â”€ data_agent.jsonl
â”‚       â”œâ”€â”€ insight_agent.jsonl
â”‚       â”œâ”€â”€ evaluator.jsonl
â”‚       â”œâ”€â”€ creative.jsonl
â”‚       â”œâ”€â”€ orchestrator.jsonl
â”‚       â”œâ”€â”€ baseline_agg.csv
â”‚       â”œâ”€â”€ current_agg.csv
â”‚       â”œâ”€â”€ hypotheses.json
â”‚       â”œâ”€â”€ validated.json
â”‚       â”œâ”€â”€ creatives.json
â”‚       â”œâ”€â”€ input_schema.json
â”‚       â”œâ”€â”€ input_summary.json
â”‚       â”œâ”€â”€ report_summary.json
â”‚       â”œâ”€â”€ metrics.json
â”‚       â””â”€â”€ run_readable.log
â””â”€â”€ tests/
    â”œâ”€â”€ test_data_agent.py
    â”œâ”€â”€ test_evaluator.py
    â”œâ”€â”€ test_pipeline.py
    â”œâ”€â”€ test_integration.py
    â”œâ”€â”€ test_metrics_layer.py
    â””â”€â”€ test_schema_drift.py
```

-----

## âš™ï¸ Configuration (`config/config.yaml`)

```yaml
python: "3.10"
random_seed: 42
confidence_min: 0.6
schema_drift_mode: "fail"   # fail | warn | off
sample_window_days: 30
data_csv: "data/synthetic_fb_ads_undergarments.csv"
output_dir: "reports"
logs_dir: "logs"
report_file: "reports/report.md"
insights_file: "reports/insights.json"
creatives_file: "reports/creatives.json"
```

-----

## ğŸ§  Architecture Overview

A production-style multi-agent pipeline:

> **Planner â†’ Data Agent â†’ Insight Agent V2 â†’ Evaluator V2 â†’ Creative Generator â†’ Report**

### 1\. Planner Agent

Creates a step-level plan for the run.

### 2\. Data Agent (Production Data Layer)

  * Schema validation
  * Type enforcement
  * Null-pattern checks
  * Configurable schema drift detection
  * Baseline vs current split
  * Time-series & campaign-level summaries
  * Input-schema & input-summary logs

### 3\. Insight Agent V2

Generates structured hypotheses using:

  * Baseline vs Current segmentation
  * Absolute & relative deltas
  * Metric trends (slope-based)
  * Frequency fatigue
  * Creative/message performance clusters
  * Spend vs ROAS correlations

**Example Hypothesis:**

```json
{
  "id": "...",
  "segment": {...},
  "metric": "ctr",
  "baseline": 0.012,
  "current": 0.007,
  "delta_abs": -0.005,
  "delta_rel": -0.41,
  "sample_size": 1820,
  "impact": "medium",
  "impact_score": 0.74,
  "confidence": 0.68,
  "evidence": {...}
}
```

### 4\. Evaluator Agent V2 (Strict Mode)

Assigns confidence, validity, reasons, contradiction detection, sample-size checks, and impact-weighted overrides.

**Evaluator output:**

```json
{
 "id": "ctr_drop_A",
 "valid": false,
 "confidence": 0.52,
 "reasons": [
   "sample_size_below_min",
   "impact_score_low",
   "confidence_below_min"
 ]
}
```

### 5\. Creative Generator

Produces grounded suggestions per low-CTR segment.

-----

## ğŸ” Observability: What Gets Logged

Every run produces a full folder under `logs/run_<timestamp>/`. This makes the system fully diagnosable by another engineer.

**Includes:**

  * Per-agent JSONL logs
  * Human-readable log (`run_readable.log`)
  * Metrics snapshot (`metrics.json`)
  * Input schema & summary
  * Hypotheses + validated insights
  * Creatives
  * Baseline & Current aggregates
  * Orchestrator trace

-----

## ğŸ“Š Lightweight Metrics Layer

Example `metrics.json`:

```json
{
  "counters": {
    "rows_loaded": 1245,
    "hypotheses_generated": 14,
    "hypotheses_validated": 6
  },
  "timings": {
    "data_load": 0.181,
    "insight_generation": 0.432,
    "evaluation": 0.117,
    "creative_generation": 0.053,
    "run_total": 1.08
  }
}
```

-----

## ğŸ§ª Running Tests

```bash
pytest -q
```

**Expected Output:**

```text
10 passed
```

**Tests cover:**

  * Schema validation
  * Drift detection
  * Insight generation
  * Strict evaluator
  * Metrics layer
  * Retry logic
  * Integration pipeline

-----

## ğŸ—ï¸ Developer Notes

### Extending Agents

Each agent is fully isolated.

  * **To add new rules or signals:** Modify `src/agents/insight_agent.py`
  * **Adding new metrics:** Update `src/utils/metrics.py`
  * **Adding new drift rules:** Modify `src/agents/data_agent.py`

-----

## ğŸ¯ V2 Submission Summary

### Engineering Deliverables

  * âœ” Strict Evaluator V2
  * âœ” InsightAgent V2 with baseline/current deltas
  * âœ” Schema validation + drift detection
  * âœ” Retry logic
  * âœ” Logging & observability per agent
  * âœ” Metrics layer
  * âœ” Full test suite (all green)
  * âœ” Deterministic, seeded pipeline

### Production Traits

  * âœ” Fail-fast behavior
  * âœ” Structured logs
  * âœ” Reproducible outputs
  * âœ” Clear thresholds
  * âœ” Safe fallbacks
  * âœ” End-to-end diagnosability

**This repository satisfies the High-Bar V2 requirements.**